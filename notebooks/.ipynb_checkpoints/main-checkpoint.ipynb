{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c023810f-d2a9-4d6c-9a8f-7894423835ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bd5c546-e988-492a-af85-91d857ddbed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4021ee25-d9f7-4722-b583-c51ef9f45726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_features, in_features, 3),\n",
    "            nn.InstanceNorm2d(in_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_features, in_features, 3),\n",
    "            nn.InstanceNorm2d(in_features)\n",
    "       )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)    \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf=64, n_downsampling=2, n_layers=6):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        encoder = []\n",
    "        \n",
    "        # input layer\n",
    "        \n",
    "        encoder += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0),\n",
    "            nn.InstanceNorm2d(ngf),\n",
    "            nn.ReLU(inplace=True) \n",
    "        ]\n",
    "\n",
    "        # downsampling\n",
    "        \n",
    "        in_features = ngf\n",
    "        out_features = ngf * 2\n",
    "        \n",
    "        for _ in range(n_downsampling):\n",
    "            encoder += [\n",
    "                nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            \n",
    "            in_features = out_features\n",
    "            out_features = in_features*2\n",
    "\n",
    "        transformer = []\n",
    "\n",
    "        # residual blocks\n",
    "        \n",
    "        for _ in range(n_layers):\n",
    "            transformer += [\n",
    "                ResidualBlock(in_features)\n",
    "            ]\n",
    "\n",
    "        decoder = []\n",
    "\n",
    "        # upsampling\n",
    "\n",
    "        out_features = in_features//2\n",
    "        \n",
    "        for _ in range(n_downsampling):\n",
    "            decoder += [\n",
    "                nn.ConvTranspose2d(in_features, out_features, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            \n",
    "            in_features = out_features\n",
    "            out_features = in_features//2\n",
    "\n",
    "        # output layer\n",
    "\n",
    "        decoder += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder)\n",
    "        self.transformer = nn.Sequential(*transformer)\n",
    "        self.decoder = nn.Sequential(*decoder)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.transformer(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        model = [\n",
    "            nn.Conv2d(input_nc, ndf, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        in_features = ndf\n",
    "        out_features = ndf * 2\n",
    "        \n",
    "        for _ in range(1, n_layers):\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, kernel_size=4, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "        \n",
    "        model += [\n",
    "            nn.Conv2d(in_features, out_features, kernel_size=4, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(out_features),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        model += [\n",
    "            nn.Conv2d(out_features, 1, kernel_size=4, padding=1)\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "174b5559-bf3b-4a80-8583-1de735dff2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_device():\n",
    "    if (torch.cuda.is_available()): return \"cuda\"\n",
    "    return \"cpu\"\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, datamodule, generator_A2B, generator_B2A, discriminator_A, discriminator_B,\n",
    "            criterion_GAN, criterion_cycle, criterion_identity, optimizer_G, optimizer_D_A, optimizer_D_B,\n",
    "            epochs, output_dir):\n",
    "        self.device = torch.device(decide_device())\n",
    "\n",
    "        self.datamodule = datamodule\n",
    "        self.generator_A2B = generator_A2B.to(self.device)\n",
    "        self.generator_B2A = generator_B2A.to(self.device)\n",
    "        self.discriminator_A = discriminator_A.to(self.device)\n",
    "        self.discriminator_B = discriminator_B.to(self.device)\n",
    "        self.criterion_GAN = criterion_GAN\n",
    "        self.criterion_cycle = criterion_cycle\n",
    "        self.criterion_identity = criterion_identity\n",
    "        self.optimizer_G = optimizer_G\n",
    "        self.optimizer_D_A = optimizer_D_A\n",
    "        self.optimizer_D_B = optimizer_D_B\n",
    "        self.epochs = epochs\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "    def fit(self):\n",
    "        train_losses_G = []\n",
    "        train_losses_D_A = []\n",
    "        train_losses_D_B = []\n",
    "        \n",
    "        val_losses_G = []\n",
    "        val_losses_D_A = []\n",
    "        val_losses_D_B = []\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss_G, train_loss_D_A, train_loss_D_B = self.train_epoch(epoch)\n",
    "            train_losses_G.append(train_loss_G)\n",
    "            train_losses_D_A.append(train_loss_D_A)\n",
    "            train_losses_D_B.append(train_loss_D_B)\n",
    "\n",
    "            val_loss_G, val_loss_D_A, val_loss_D_B = self.val_epoch(epoch)\n",
    "            val_losses_G.append(val_loss_G)\n",
    "            val_losses_D_A.append(val_loss_D_A)\n",
    "            val_losses_D_B.append(val_loss_D_B)\n",
    "\n",
    "        self.plot_loss(filename='generator_loss.png', caption='Generator loss', train_losses=train_losses_G, val_losses=val_losses_G)\n",
    "        self.plot_loss(filename='discriminator_A_loss.png', caption='Discriminator A loss', train_losses=train_losses_D_A, val_losses=val_losses_D_A)\n",
    "        self.plot_loss(filename='discriminator_B_loss.png', caption='Discriminator B loss', train_losses=train_losses_D_B, val_losses=val_losses_D_B)\n",
    "          \n",
    "    def train_epoch(self, epoch):\n",
    "        dataloader = self.datamodule.train_loader\n",
    "\n",
    "        self.model.train()\n",
    "        total_loss_G = 0.0\n",
    "        total_loss_D_A = 0.0\n",
    "        total_loss_D_B = 0.0\n",
    "\n",
    "        target_dims = (3, 64, 64)\n",
    "        target_real = torch.full(target_dims, 1)\n",
    "        target_fake = torch.full(target_dims, 0)\n",
    "\n",
    "        for real_A, real_B in dataloader:\n",
    "            real_A = real_A.to(self.device)\n",
    "            real_B = real_B.to(self.device)\n",
    "\n",
    "            # TRAIN GENERATORS A2B, B2A\n",
    "            \n",
    "            self.optimizer_G.zero_grad()\n",
    "\n",
    "            # identity loss\n",
    "            \n",
    "            identity_A = self.generator_B2A(real_A)\n",
    "            loss_identity_A = self.criterion_identity(identity_A, real_A) * 5.0\n",
    "            \n",
    "            identity_B = self.generator_A2B(real_B)\n",
    "            loss_identity_B = self.criterion_identity(identity_B, real_B) * 5.0\n",
    "\n",
    "            # GAN loss\n",
    "            \n",
    "            fake_A = self.generator_B2A(real_B)\n",
    "            pred_fake = self.discriminator_A(fake_A)\n",
    "            loss_GAN_B2A = self.criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "            fake_B = self.generator_A2B(real_A)\n",
    "            pred_fake = self.discriminator_B(fake_B)\n",
    "            loss_GAN_A2B = self.criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "            # cycle loss\n",
    "\n",
    "            recovered_A = self.generator_B2A(fake_B)\n",
    "            loss_cycle_B2A = self.cricerion_cycle(recovered_A, real_A) * 10.0\n",
    "\n",
    "            recovered_B = self.generator_A2B(fake_A)\n",
    "            loss_cycle_A2B = self.cricerion_cycle(recovered_B, real_B) * 10.0\n",
    "\n",
    "            loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_A2B + loss_cycle_B2A\n",
    "            total_loss_G += loss_G.item()\n",
    "            \n",
    "            loss_G.backward()\n",
    "            self.optimizer_G.step()\n",
    "\n",
    "            # TRAIN DISCRIMINATOR A\n",
    "\n",
    "            self.optimizer_D_A.zero_grad()\n",
    "\n",
    "            # real loss\n",
    "\n",
    "            pred_real = self.discriminator_A(real_A)\n",
    "            loss_D_A_real = self.criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # fake loss\n",
    "\n",
    "            pred_fake = self.discriminator_B(fake_A)\n",
    "            loss_D_A_fake = self.criterion_GAN(pred_fake, target_fake)\n",
    "            \n",
    "            loss_D_A = (loss_D_A_real + loss_D_A_fake) * 0.5\n",
    "            total_loss_D_A += loss_D_A.item()\n",
    "        \n",
    "            loss_D_A.backward()\n",
    "            self.optimizer_D_A.step()\n",
    "        \n",
    "            # TRAIN DISCRIMINATOR B\n",
    "\n",
    "            self.optimizer_D_B.zero_grad()\n",
    "\n",
    "            # real loss\n",
    "\n",
    "            pred_real = self.discriminator_B(real_B)\n",
    "            loss_D_B_real = self.criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # fake loss\n",
    "\n",
    "            pred_fake = self.discriminator_B(fake_B)\n",
    "            loss_D_B_fake = self.criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "            loss_D_B = (loss_D_B_real + loss_D_B_fake) * 0.5\n",
    "            total_loss_D_B += loss_D_B.item()\n",
    "        \n",
    "            loss_D_B.backward()\n",
    "            self.optimizer_D_B.step()\n",
    "\n",
    "        avg_loss_G = total_loss_G / len(dataloader)\n",
    "        avg_loss_D_A = total_loss_D_A / len(dataloader)\n",
    "        avg_loss_D_B = total_loss_D_B / len(dataloader)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Training loss: generator = {avg_loss_G}; discriminator A = {avg_loss_D_A}; discriminator B = {avg_loss_D_B}')\n",
    "\n",
    "        return avg_loss_G, avg_loss_D_A, avg_loss_D_B\n",
    "\n",
    "    def val_epoch(self, epoch):\n",
    "        dataloader = self.datamodule.val_loader\n",
    "\n",
    "        self.model.eval()\n",
    "        total_loss_G = 0.0\n",
    "        total_loss_D_A = 0.0\n",
    "        total_loss_D_B = 0.0\n",
    "\n",
    "        target_dims = (3, 64, 64)\n",
    "        target_real = torch.full(target_dims, 1)\n",
    "        target_fake = torch.full(target_dims, 0)\n",
    "        \n",
    "        for real_A, real_B in dataloader:\n",
    "            real_A = real_A.to(self.device)\n",
    "            real_B = real_B.to(self.device)\n",
    "\n",
    "            # TRAIN GENERATORS A2B, B2A\n",
    "            \n",
    "            self.optimizer_G.zero_grad()\n",
    "\n",
    "            # identity loss\n",
    "            \n",
    "            identity_A = self.generator_B2A(real_A)\n",
    "            loss_identity_A = self.criterion_identity(identity_A, real_A)*5.0\n",
    "            \n",
    "            identity_B = self.generator_A2B(real_B)\n",
    "            loss_identity_B = self.criterion_identity(identity_B, real_B)*5.0\n",
    "\n",
    "            # GAN loss\n",
    "            \n",
    "            fake_A = self.generator_B2A(real_B)\n",
    "            pred_fake = self.discriminator_A(fake_A)\n",
    "            loss_GAN_B2A = self.criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "            fake_B = self.generator_A2B(real_A)\n",
    "            pred_fake = self.discriminator_B(fake_B)\n",
    "            loss_GAN_B2A = self.criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "            # cycle loss\n",
    "\n",
    "            recovered_A = self.generator_B2A(fake_B)\n",
    "            loss_cycle_ABA = self.cricerion_cycle(recovered_A, real_A) * 10.0\n",
    "\n",
    "            recovered_B = self.generator_A2B(fake_A)\n",
    "            loss_cycle_BAB = self.cricerion_cycle(recovered_B, real_B) * 10.0\n",
    "\n",
    "            loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "            total_loss_G += loss_G.item()\n",
    "\n",
    "            # TRAIN DISCRIMINATOR A\n",
    "\n",
    "            self.optimizer_D_A.zero_grad()\n",
    "\n",
    "            # real loss\n",
    "\n",
    "            pred_real = self.discriminator_A(real_A)\n",
    "            loss_D_A_real = self.criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # fake loss\n",
    "\n",
    "            pred_fake = self.discriminator_A(fake_A)\n",
    "            loss_D_A_fake = self.criterion_GAN(pred_fake, target_fake)\n",
    "            \n",
    "            loss_D_A = (loss_D_A_real + loss_D_A_fake) * 0.5\n",
    "            total_loss_D_A += loss_D_A.item()\n",
    "        \n",
    "            # TRAIN DISCRIMINATOR B\n",
    "\n",
    "            self.optimizer_D_B.zero_grad()\n",
    "\n",
    "            # real loss\n",
    "\n",
    "            pred_real = self.discriminator_B(real_B)\n",
    "            loss_D_B_real = self.criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # fake loss\n",
    "\n",
    "            pred_fake = self.discriminator_B(fake_B)\n",
    "            loss_D_B_fake = self.criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "            loss_D_B = (loss_D_B_real + loss_D_B_fake) * 0.5\n",
    "            total_loss_D_B += loss_D_B.item()\n",
    "\n",
    "        avg_loss_G = total_loss_G / len(dataloader)\n",
    "        avg_loss_D_A = total_loss_D_A / len(dataloader)\n",
    "        avg_loss_D_B = total_loss_D_B / len(dataloader)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Validation loss: generator = {avg_loss_G}; discriminator A = {avg_loss_D_A}; discriminator B = {avg_loss_D_B}')\n",
    "\n",
    "        return avg_loss_G, avg_loss_D_A, avg_loss_D_B\n",
    "\n",
    "    def plot_loss(self, filename, caption, train_losses, val_losses):\n",
    "        filename = os.path.join(self.output_dir, filename)\n",
    "\n",
    "        plt.clf()\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.plot(val_losses, label='Val Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(caption)\n",
    "        plt.legend()\n",
    "        plt.savefig(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72487cc3-8bf9-47f7-864f-a81deca948c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
